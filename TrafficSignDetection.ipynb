{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtGHNEXIuYmpYFuULiYMQj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngminh124/traffic-sign-detection/blob/main/TrafficSignDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Gắn kết Google Drive trước để kiểm tra dữ liệu\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except Exception as e:\n",
        "    print(f\"Lỗi khi gắn kết Google Drive: {e}\")\n",
        "    raise\n",
        "\n",
        "# Kiểm tra xem dữ liệu có tồn tại trong Drive hay không\n",
        "dataset_path = '/content/drive/MyDrive/road-sign-detection'\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(\"Không tìm thấy dữ liệu trong Drive. Đang tải và giải nén...\")\n",
        "\n",
        "    # Tải lên khóa API Kaggle\n",
        "    try:\n",
        "        uploaded = files.upload()\n",
        "        if 'kaggle.json' not in uploaded:\n",
        "            raise FileNotFoundError(\"Vui lòng tải lên tệp kaggle.json.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi tải lên khóa API Kaggle: {e}\")\n",
        "        raise\n",
        "\n",
        "    # Thiết lập Kaggle\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "    !kaggle --version\n",
        "\n",
        "    # Tải dữ liệu từ Kaggle\n",
        "    !kaggle datasets download -d andrewmvd/road-sign-detection -p /content/\n",
        "\n",
        "    # Xóa các thư mục annotations và images nếu đã tồn tại\n",
        "    !rm -rf /content/annotations /content/images\n",
        "\n",
        "    # Giải nén dữ liệu\n",
        "    !unzip /content/road-sign-detection.zip -d /content/\n",
        "\n",
        "    # Sao chép dữ liệu vào Drive\n",
        "    !mkdir -p /content/drive/MyDrive/road-sign-detection/\n",
        "else:\n",
        "    print(\"Dữ liệu đã có sẵn trong Drive. Không cần tải lại.\")\n",
        "if not os.path.exists('/content/images') or not os.path.exists('/content/annotations'):\n",
        "    print(\"Không tìm thấy thư mục images hoặc annotations trong /content/. Đang sao chép từ Drive...\")\n",
        "    if os.path.exists(os.path.join(dataset_path, 'images')) and os.path.exists(os.path.join(dataset_path, 'annotations')):\n",
        "        !cp -r /content/drive/MyDrive/road-sign-detection/images /content/\n",
        "        !cp -r /content/drive/MyDrive/road-sign-detection/annotations /content/\n",
        "        print(\"Đã sao chép dữ liệu từ Drive sang /content/.\")\n",
        "    else:\n",
        "        print(\"Lỗi: Không tìm thấy thư mục images hoặc annotations trong Drive. Vui lòng kiểm tra lại.\")\n",
        "else:\n",
        "    print(\"Thư mục images và annotations đã tồn tại trong /content/. Bỏ qua bước sao chép.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Pa5raLGM0hGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e66d83-9348-41e6-9b40-e4717c0cd397"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dữ liệu đã có sẵn trong Drive. Không cần tải lại.\n",
            "Thư mục images và annotations đã tồn tại trong /content/. Bỏ qua bước sao chép.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "AaALiAbrv3J1"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "from skimage.transform import resize\n",
        "from skimage import feature\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# đọc 1 file xml cụ thể sử dụng ElementTree\n",
        "\n",
        "xml_file = '/content/annotations/road0.xml'\n",
        "tree = ET.parse(xml_file)\n",
        "root = tree.getroot()\n",
        "folder_name = root.find('folder').text\n",
        "filename = root.find('filename').text\n",
        "print (f'Folder: {folder_name}')\n",
        "print(f'Filename: {filename}')\n",
        "\n",
        "# đọc tất cả các object có trong thẻ object của file xml đó\n",
        "\n",
        "for obj in root.findall('object'):\n",
        "  classname=obj.find('name').text\n",
        "  xmin=int(obj.find('bndbox/xmin').text)\n",
        "  ymin=int(obj.find('bndbox/ymin').text)\n",
        "  xmax=int(obj.find('bndbox/xmax').text)\n",
        "  ymax=int(obj.find('bndbox/ymax').text)\n",
        "print(f'Class name: {classname}')\n",
        "print(f'Bounding box: {(xmin, ymin, xmax, ymax)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HozGhBnK2HJh",
        "outputId": "246e0e08-d46d-4a73-9014-fad2448b21b0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder: images\n",
            "Filename: road0.png\n",
            "Class name: trafficlight\n",
            "Bounding box: (98, 62, 208, 232)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# đọc toàn bộ datasets\n",
        "# đọc qua các file annotations bằng hàm listdr của module os\n",
        "# đọc ảnh thông qua thư viện opencv\n",
        "annotations_dir = '/content/annotations'\n",
        "img_dir = '/content/images'\n",
        "img_lst = []\n",
        "label_lst = []\n",
        "for xml_file in os.listdir (annotations_dir):\n",
        "\n",
        "  xml_filepath = os.path.join(annotations_dir, xml_file)\n",
        "\n",
        "  tree=ET.parse(xml_filepath)\n",
        "\n",
        "  root=tree.getroot()\n",
        "\n",
        "  folder = root.find('folder').text\n",
        "\n",
        "  img_filename = root.find('filename').text\n",
        "\n",
        "  img_filepath = os.path.join(img_dir, img_filename)\n",
        "\n",
        "  img = cv2.imread(img_filepath)\n",
        "  for obj in root.findall('object'):\n",
        "      classname = obj.find('name').text\n",
        "      if classname == 'trafficlight':\n",
        "          continue\n",
        "      xmin = int(obj.find('bndbox/xmin').text)\n",
        "      ymin= int(obj.find('bndbox/ymin').text)\n",
        "      xmax = int(obj.find('bndbox/xmax').text)\n",
        "      ymax = int(obj.find('bndbox/ymax').text)\n",
        "      object_img = img[ymin:ymax, xmin: xmax]\n",
        "      img_lst.append(object_img)\n",
        "      label_lst.append(classname)\n",
        "print(f'Number of images in datasets: {len(img_lst)}')\n",
        "print(f'Classes names: {list(set(label_lst))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0dphhwN3bTh",
        "outputId": "d209e91b-a1b8-4ed6-dce3-8ef22f7f6b97"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in datasets: 1074\n",
            "Classes names: ['crosswalk', 'stop', 'speedlimit']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'original shape: {img_lst[0].shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfZ5mWtt8iOJ",
        "outputId": "84d91bbc-9dcd-42d9-d308-70aeaab0934b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original shape: (38, 38, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chuyển shape sử dụng flatten của ảnh gốc ban đầu từ vector 3D thành vector 1D để phục vụ cho việc train theo model SVM\n",
        "flattened_img =img_lst[0].flatten()\n",
        "print(f'flattend shape: {flattened_img.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cMyY0gX9naS",
        "outputId": "3f2d6204-0abb-4794-870e-f200c839278f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flattend shape: (4332,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sử dụng HOG thay vì flatten\n",
        "def preprocess_img(img):\n",
        "  if len(img.shape) > 2:\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img=img.astype(np.float32)\n",
        "  resized_img = resize(\n",
        "      img,\n",
        "      output_shape=(32, 32),\n",
        "      anti_aliasing=True\n",
        "  )\n",
        "  hog_feature = feature.hog(\n",
        "      resized_img,\n",
        "      orientations=9,\n",
        "      pixels_per_cell=(8, 8),\n",
        "      cells_per_block=(2, 2),\n",
        "      transform_sqrt=True,\n",
        "      block_norm=\"L2\",\n",
        "      feature_vector=True\n",
        "  )\n",
        "  return hog_feature.reshape(1,-1)"
      ],
      "metadata": {
        "id": "ppeHrH3HFOIz"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_features_lst =[]\n",
        "for img in img_lst:\n",
        "  hog_feature = preprocess_img(img)\n",
        "  img_features_lst.append(hog_feature)\n",
        "img_features= np.array(img_features_lst)\n",
        "print(\"X shape: \")\n",
        "print(img_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KougEfqyGfgD",
        "outputId": "5fcc9981-54ab-473f-bbb0-0f8932907b82"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: \n",
            "(1074, 1, 324)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode label thành dạng số để phục vụ cho việc train\n",
        "label_encoder= LabelEncoder()\n",
        "encoded_labels= label_encoder.fit_transform(label_lst)\n",
        "print(label_encoder.classes_)\n",
        "encoded_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nD2fGyUJkjw",
        "outputId": "e7870a64-3505-4df3-9832-78df33aa1ae4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['crosswalk' 'speedlimit' 'stop']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_state=0\n",
        "test_size=0.3\n",
        "is_shuffle= True\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    img_features, encoded_labels,\n",
        "    test_size=test_size,\n",
        "    random_state=random_state,\n",
        "    shuffle=is_shuffle\n",
        ")"
      ],
      "metadata": {
        "id": "8bIRPaydKO69"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sửa lỗi bằng cách flatten mỗi sample\n",
        "X_train_fixed = []\n",
        "for sample in X_train:\n",
        "    if len(sample.shape) == 2:  # Nếu sample là 2D\n",
        "        X_train_fixed.append(sample.flatten())  # Flatten thành 1D\n",
        "    else:\n",
        "        X_train_fixed.append(sample)\n",
        "\n",
        "X_train_fixed = np.array(X_train_fixed)\n",
        "\n",
        "# Tương tự cho X_val\n",
        "X_val_fixed = []\n",
        "for sample in X_val:\n",
        "    if len(sample.shape) == 2:\n",
        "        X_val_fixed.append(sample.flatten())\n",
        "    else:\n",
        "        X_val_fixed.append(sample)\n",
        "\n",
        "X_val_fixed = np.array(X_val_fixed)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train_fixed)\n",
        "X_val = scaler.transform(X_val_fixed)"
      ],
      "metadata": {
        "id": "osgtaXo-LWHH"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train và đánh giá model\n",
        "clf= SVC(\n",
        "    kernel='rbf',\n",
        "    random_state=random_state,\n",
        "    probability=True,\n",
        "    C=0.5\n",
        "\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred=clf.predict(X_val)\n",
        "score=accuracy_score(y_pred, y_val)\n",
        "print(f'Evaluation results on val set')\n",
        "print(f'Accurancy: {score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HkUGa_UMfoH",
        "outputId": "880e69dd-cf8a-4761-a61e-2c6f4365576a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results on val set\n",
            "Accurancy: 0.9721362229102167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = img_lst[1]\n",
        "normalized_img = preprocess_img(input_img)\n",
        "\n",
        "# Vì preprocess_img() đã trả về shape (1, n_features), không cần đặt trong []\n",
        "y_pred = clf.predict(normalized_img)[0]\n",
        "print(f'Normal prediction: {y_pred}')\n",
        "\n",
        "y_pred_prob = clf.predict_proba(normalized_img)\n",
        "prediction = np.argmax(y_pred_prob)\n",
        "y_pred_prob = [f'{p:.10f}' for p in y_pred_prob[0]]\n",
        "print(f'Probability of each class: {y_pred_prob}')\n",
        "print(f'Class with highest probability: {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px1GUlyNOae9",
        "outputId": "a2627a8d-c531-441d-ad3e-bc92767bf18f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal prediction: 1\n",
            "Probability of each class: ['0.0000000076', '0.9999047308', '0.0000952616']\n",
            "Class with highest probability: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lấy danh sách các cửa sổ cắt được\n",
        "def sliding_window(img, window_sizes, stride, scale_factor):\n",
        "    img_height, img_width = img.shape[:2]\n",
        "    windows = []\n",
        "    for window_size in window_sizes:\n",
        "        window_width, window_height = window_size\n",
        "        for ymin in range(0, img_height - window_height + 1, stride):\n",
        "            for xmin in range(0, img_width-window_width + 1, stride):\n",
        "                xmax = xmin + window_width\n",
        "                ymax = ymin + window_height\n",
        "                windows.append([xmin, ymin, xmax, ymax])\n",
        "    return windows"
      ],
      "metadata": {
        "id": "Nr30f0_CCYGy"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale ảnh để bắt được các object nhỏ so với kích thước ảnh\n",
        "def pyramid(img, scale=0.8, min_size=(32, 32)):\n",
        "    acc_scale = 1.0\n",
        "    pyramid_imgs = [(img, acc_scale)]\n",
        "    i = 0\n",
        "    while True:\n",
        "        acc_scale = acc_scale * scale\n",
        "        h = int(img.shape[0] * acc_scale)\n",
        "        w = int(img.shape[1] * acc_scale)\n",
        "        if h<min_size[1] or w < min_size[0]:\n",
        "            break\n",
        "        img = cv2.resize(img, (w, h))\n",
        "        pyramid_imgs.append((img, acc_scale * (scale ** i)))\n",
        "        i += 1\n",
        "    return pyramid_imgs"
      ],
      "metadata": {
        "id": "q_wORaBqIIQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_bbox(img, bboxes, label_encoder):\n",
        "    # Tạo bản copy để không thay đổi ảnh gốc\n",
        "    img_viz = img.copy()\n",
        "    # Chuyển sang RGB để vẽ (nếu ảnh đầu vào là BGR)\n",
        "    img_viz = cv2.cvtColor(img_viz, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    for box in bboxes:\n",
        "        xmin, ymin, xmax, ymax, predict_id, conf_score = box\n",
        "        # Vẽ bounding box\n",
        "        cv2.rectangle(img_viz, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "\n",
        "        # Lấy tên class\n",
        "        try:\n",
        "            classname = label_encoder.inverse_transform([predict_id])[0]\n",
        "        except:\n",
        "            classname = str(predict_id)\n",
        "\n",
        "        # Tạo label text\n",
        "        label = f\"{classname} {conf_score:.2f}\"\n",
        "\n",
        "        # Tính toán kích thước text\n",
        "        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
        "\n",
        "        # Vẽ nền cho text\n",
        "        cv2.rectangle(img_viz, (xmin, ymin - 20), (xmin + w, ymin), (0, 255, 0), -1)\n",
        "\n",
        "        # Vẽ text\n",
        "        cv2.putText(img_viz, label, (xmin, ymin - 5),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)\n",
        "\n",
        "    return img_viz"
      ],
      "metadata": {
        "id": "TeCizIWHM_Ss"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_img = preprocess_img(object_img)\n",
        "print(f\"Shape of preprocessed_img: {preprocessed_img.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsPt9kx9Sbog",
        "outputId": "87d77501-e0e5-4451-da7c-c980d2639751"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of preprocessed_img: (1, 324)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sử dụng pyramid images để có thể bắt được các biển báo với kích thước nhỏ so với ảnh gốc ban đầu\n",
        "for pyramid_img_info in pyramid_imgs:\n",
        "    pyramid_img, scale_factor = pyramid_img_info\n",
        "    window_lst = sliding_window(\n",
        "        pyramid_img,\n",
        "        window_sizes=window_sizes,\n",
        "        stride=stride,\n",
        "        scale_factor=scale_factor\n",
        "    )\n",
        "    for window in window_lst:\n",
        "      xmin, ymin, xmax, ymax = window\n",
        "      object_img = pyramid_img[ymin:ymax, xmin:xmax]\n",
        "      preprocessed_img = preprocess_img(object_img)  # Trả về (1, n_features)\n",
        "\n",
        "      # Không cần đặt trong [] vì đã là 2D\n",
        "      normalized_img = scaler.transform(preprocessed_img)[0]\n",
        "      decision = clf.predict_proba(preprocessed_img)[0]\n",
        "\n",
        "      if np.all(decision < conf_threshold):\n",
        "          continue\n",
        "      else:\n",
        "          predict_id = np.argmax(decision)\n",
        "          conf_score = decision[predict_id]\n",
        "          xmin = int(xmin / scale_factor)\n",
        "          ymin = int(ymin / scale_factor)\n",
        "          xmax = int(xmax / scale_factor)\n",
        "          ymax = int(ymax / scale_factor)\n",
        "          bboxes.append([xmin, ymin, xmax, ymax, predict_id, conf_score])"
      ],
      "metadata": {
        "id": "DUstMtG9OEHc"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tính chỉ số iou để loại bỏ các bounding box bị trùng lặp với 1 biển báo\n",
        "def iou_bbox(box1, box2):\n",
        "    b1_x1, b1_y1, b1_x2, b1_y2 = box1[0], box1[1], box1[2], box1[3]\n",
        "    b2_x1, b2_y1, b2_x2, b2_y2 = box2[0], box2[1], box2[2], box2[3]\n",
        "#Step 1: Tính diện tích phần giao nhau\n",
        "    x1 = max(b1_x1, b2_x1)\n",
        "    y1 = max(b1_y1, b2_y1)\n",
        "    x2 = min(b1_x2, b2_x2)\n",
        "    y2 = min(b1_y2, b2_y2)\n",
        "    inter = max((x2-x1), 0)*max((y2-y1), 0)\n",
        "#Step 2: Tính diện tích phần hợp nhau\n",
        "    box1_area = abs((b1_x2 - b1_x1) * (b1_y2 - b1_y1))\n",
        "    box2_area = abs((b2_x2 - b2_x1) * (b2_y2 - b2_y1))\n",
        "    union = float(box1_area + box2_area - inter)\n",
        "    iou=inter / union\n",
        "    return iou"
      ],
      "metadata": {
        "id": "TI4edx_qWHpF"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_iou(box, boxes, area, areas):\n",
        "    xx1 = np.maximum(box[0], boxes[:, 0])\n",
        "    yy1 = np.maximum(box[1], boxes[:, 1])\n",
        "    xx2 = np.minimum(box[2], boxes[:, 2])\n",
        "    yy2 = np.minimum(box[3], boxes[:, 3])\n",
        "\n",
        "    w = np.maximum(0, xx2 - xx1)\n",
        "    h = np.maximum(0, yy2 - yy1)\n",
        "\n",
        "    inter = w * h\n",
        "    union = area + areas - inter\n",
        "\n",
        "    return inter / union"
      ],
      "metadata": {
        "id": "mGu2nNpxS_zh"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sử dụng thuật toán non maximun suppression nhằm loại bỏ các bounding box có độ tin cậy thấp và hoặc bị trùng lặp dựa trên ngương iou đã được tính\n",
        "def nms (bboxes, iou_threshold):\n",
        "  if not bboxes:\n",
        "    return []\n",
        "  scores = np.array([bbox[5] for bbox in bboxes])\n",
        "  sorted_indices = np.argsort(scores) [::-1]\n",
        "  xmin = np.array([bbox[0] for bbox in bboxes])\n",
        "  ymin = np.array([bbox[1] for bbox in bboxes])\n",
        "  xmax = np.array([bbox[2] for bbox in bboxes])\n",
        "  ymax = np.array([bbox[3] for bbox in bboxes])\n",
        "  areas=(xmax - xmin + 1) * (ymax - ymin + 1)\n",
        "  keep = []\n",
        "  while sorted_indices.size > 0:\n",
        "    i=sorted_indices[0]\n",
        "    keep.append(i)\n",
        "    iou=compute_iou(\n",
        "      [xmin[i], ymin[i], xmax[i], ymax[i]],\n",
        "      np.array(\n",
        "        [\n",
        "          xmin [sorted_indices [1:]],\n",
        "          ymin [sorted_indices [1:]],\n",
        "          xmax [sorted_indices [1:]],\n",
        "          ymax [sorted_indices [1:]]]\n",
        "      ).T,\n",
        "      areas[i],\n",
        "      areas[sorted_indices[1:]]\n",
        "    )\n",
        "    idx_to_keep=np.where(iou <= iou_threshold)[0]\n",
        "    sorted_indices=sorted_indices [idx_to_keep + 1]\n",
        "  return [bboxes[i] for i in keep]"
      ],
      "metadata": {
        "id": "nC1xL58LXzAW"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Tạo thư mục output nếu chưa có\n",
        "output_dir = '/content/output'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Configuration\n",
        "img_dir = '/content/images'\n",
        "img_filename_lst = os.listdir(img_dir)[:20]\n",
        "conf_threshold = 0.95\n",
        "iou_threshold = 0.5\n",
        "stride = 12\n",
        "window_sizes = [\n",
        "    (32, 32),\n",
        "    (64, 64),\n",
        "    (128, 128)\n",
        "]\n",
        "\n",
        "# Process each image\n",
        "for img_filename in img_filename_lst:\n",
        "    start_time = time.time()\n",
        "    img_filepath = os.path.join(img_dir, img_filename)\n",
        "    print(f\"Processing: {img_filepath}\")\n",
        "\n",
        "    bboxes = []\n",
        "    img = cv2.imread(img_filepath)\n",
        "    if img is None:\n",
        "        print(f\"Could not read image: {img_filename}\")\n",
        "        continue\n",
        "\n",
        "    pyramid_imgs = pyramid(img)\n",
        "\n",
        "    for pyramid_img_info in pyramid_imgs:\n",
        "        pyramid_img, scale_factor = pyramid_img_info\n",
        "        window_lst = sliding_window(\n",
        "            pyramid_img,\n",
        "            window_sizes=window_sizes,\n",
        "            stride=stride,\n",
        "            scale_factor=scale_factor\n",
        "        )\n",
        "\n",
        "        for window in window_lst:\n",
        "            xmin, ymin, xmax, ymax = window\n",
        "            object_img = pyramid_img[ymin:ymax, xmin:xmax]\n",
        "\n",
        "            if object_img.size == 0:\n",
        "                continue  # Bỏ qua nếu ảnh nhỏ hơn window\n",
        "\n",
        "            preprocessed_img = preprocess_img(object_img)\n",
        "            normalized_img = scaler.transform(preprocessed_img)\n",
        "            decision = clf.predict_proba(normalized_img)[0]\n",
        "\n",
        "            if np.all(decision < conf_threshold):\n",
        "                continue\n",
        "            else:\n",
        "                predict_id = np.argmax(decision)\n",
        "                conf_score = decision[predict_id]\n",
        "\n",
        "                # Scale coordinates back to original image\n",
        "                xmin = int(xmin / scale_factor)\n",
        "                ymin = int(ymin / scale_factor)\n",
        "                xmax = int(xmax / scale_factor)\n",
        "                ymax = int(ymax / scale_factor)\n",
        "\n",
        "                bboxes.append(\n",
        "                    (xmin, ymin, xmax, ymax, predict_id, conf_score)\n",
        "                )\n",
        "\n",
        "    # Thông báo số bbox trước khi NMS\n",
        "    print(f\"[INFO] Before NMS: {len(bboxes)} bboxes found in {img_filename}\")\n",
        "\n",
        "    # Apply Non-Maximum Suppression\n",
        "    bboxes = nms(bboxes, iou_threshold)\n",
        "    print(f\"[INFO] After NMS: {len(bboxes)} bboxes kept\")\n",
        "\n",
        "    # Visualize và lưu ảnh nếu có bbox\n",
        "    if len(bboxes) > 0:\n",
        "        img_with_bbox = visualize_bbox(img, bboxes, label_encoder)\n",
        "        output_path = os.path.join(output_dir, img_filename)\n",
        "        # Chuyển màu về BGR trước khi lưu\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(img_with_bbox, cv2.COLOR_RGB2BGR))\n",
        "        print(f\"[SAVED] Result saved to {output_path}\")\n",
        "    else:\n",
        "        print(f\"[SKIPPED] No object detected in {img_filename}\")\n",
        "\n",
        "    print('Time process:', time.time() - start_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFGTw9mUNRzI",
        "outputId": "1f89df71-f100-4365-f1f4-8674d2458de2"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: /content/images/road176.png\n",
            "[INFO] Before NMS: 0 bboxes found in road176.png\n",
            "[INFO] After NMS: 0 bboxes kept\n",
            "[SKIPPED] No object detected in road176.png\n",
            "Time process: 2.5587360858917236\n",
            "Processing: /content/images/road263.png\n",
            "[INFO] Before NMS: 2 bboxes found in road263.png\n",
            "[INFO] After NMS: 1 bboxes kept\n",
            "[SAVED] Result saved to /content/output/road263.png\n",
            "Time process: 2.602519989013672\n",
            "Processing: /content/images/road753.png\n",
            "[INFO] Before NMS: 2 bboxes found in road753.png\n",
            "[INFO] After NMS: 2 bboxes kept\n",
            "[SAVED] Result saved to /content/output/road753.png\n",
            "Time process: 3.285290002822876\n",
            "Processing: /content/images/road373.png\n",
            "[INFO] Before NMS: 0 bboxes found in road373.png\n",
            "[INFO] After NMS: 0 bboxes kept\n",
            "[SKIPPED] No object detected in road373.png\n",
            "Time process: 2.7092678546905518\n",
            "Processing: /content/images/road45.png\n",
            "[INFO] Before NMS: 0 bboxes found in road45.png\n",
            "[INFO] After NMS: 0 bboxes kept\n",
            "[SKIPPED] No object detected in road45.png\n",
            "Time process: 2.273534059524536\n",
            "Processing: /content/images/road366.png\n",
            "[INFO] Before NMS: 0 bboxes found in road366.png\n",
            "[INFO] After NMS: 0 bboxes kept\n",
            "[SKIPPED] No object detected in road366.png\n",
            "Time process: 2.6245315074920654\n",
            "Processing: /content/images/road809.png\n",
            "[INFO] Before NMS: 0 bboxes found in road809.png\n",
            "[INFO] After NMS: 0 bboxes kept\n",
            "[SKIPPED] No object detected in road809.png\n",
            "Time process: 2.9462764263153076\n",
            "Processing: /content/images/road160.png\n",
            "[INFO] Before NMS: 1 bboxes found in road160.png\n",
            "[INFO] After NMS: 1 bboxes kept\n",
            "[SAVED] Result saved to /content/output/road160.png\n",
            "Time process: 3.034973621368408\n",
            "Processing: /content/images/road418.png\n",
            "[INFO] Before NMS: 0 bboxes found in road418.png\n",
            "[INFO] After NMS: 0 bboxes kept\n",
            "[SKIPPED] No object detected in road418.png\n",
            "Time process: 2.732260227203369\n",
            "Processing: /content/images/road287.png\n",
            "[INFO] Before NMS: 0 bboxes found in road287.png\n",
            "[INFO] After NMS: 0 bboxes kept\n",
            "[SKIPPED] No object detected in road287.png\n",
            "Time process: 3.2810115814208984\n",
            "Processing: /content/images/road191.png\n",
            "[INFO] Before NMS: 1 bboxes found in road191.png\n",
            "[INFO] After NMS: 1 bboxes kept\n",
            "[SAVED] Result saved to /content/output/road191.png\n",
            "Time process: 2.841684341430664\n",
            "Processing: /content/images/road632.png\n",
            "[INFO] Before NMS: 1 bboxes found in road632.png\n",
            "[INFO] After NMS: 1 bboxes kept\n",
            "[SAVED] Result saved to /content/output/road632.png\n",
            "Time process: 3.092048168182373\n",
            "Processing: /content/images/road374.png\n",
            "[INFO] Before NMS: 1 bboxes found in road374.png\n",
            "[INFO] After NMS: 1 bboxes kept\n",
            "[SAVED] Result saved to /content/output/road374.png\n",
            "Time process: 2.639392375946045\n",
            "Processing: /content/images/road393.png\n",
            "[INFO] Before NMS: 0 bboxes found in road393.png\n",
            "[INFO] After NMS: 0 bboxes kept\n",
            "[SKIPPED] No object detected in road393.png\n",
            "Time process: 2.860400676727295\n",
            "Processing: /content/images/road506.png\n",
            "[INFO] Before NMS: 2 bboxes found in road506.png\n",
            "[INFO] After NMS: 1 bboxes kept\n",
            "[SAVED] Result saved to /content/output/road506.png\n",
            "Time process: 2.619917869567871\n",
            "Processing: /content/images/road549.png\n",
            "[INFO] Before NMS: 2 bboxes found in road549.png\n",
            "[INFO] After NMS: 2 bboxes kept\n",
            "[SAVED] Result saved to /content/output/road549.png\n",
            "Time process: 3.3232641220092773\n",
            "Processing: /content/images/road436.png\n",
            "[INFO] Before NMS: 1 bboxes found in road436.png\n",
            "[INFO] After NMS: 1 bboxes kept\n",
            "[SAVED] Result saved to /content/output/road436.png\n",
            "Time process: 2.651322841644287\n",
            "Processing: /content/images/road805.png\n",
            "[INFO] Before NMS: 2 bboxes found in road805.png\n",
            "[INFO] After NMS: 1 bboxes kept\n",
            "[SAVED] Result saved to /content/output/road805.png\n",
            "Time process: 2.5850303173065186\n",
            "Processing: /content/images/road304.png\n",
            "[INFO] Before NMS: 0 bboxes found in road304.png\n",
            "[INFO] After NMS: 0 bboxes kept\n",
            "[SKIPPED] No object detected in road304.png\n",
            "Time process: 2.6157829761505127\n",
            "Processing: /content/images/road152.png\n",
            "[INFO] Before NMS: 13 bboxes found in road152.png\n",
            "[INFO] After NMS: 2 bboxes kept\n",
            "[SAVED] Result saved to /content/output/road152.png\n",
            "Time process: 1.986907958984375\n"
          ]
        }
      ]
    }
  ]
}